This README written by John Barron

singh.c contains an implementation of Singh's technique. (See the TR
to see the differences between our implementation and Singh's) In
addition to singh.c you need svddouble.f (a double precision Limpack
routine) To compile:
	make -f makesingh
This program requires a lot of time to run (if we had used a pyramid
structure as suggest in Singh's book it would be much faster and handle
larger motions).  An example of a run:

singh newbinarytreet. 20 /data/images1/BURKITT/testdata /data/images2/SINGH -B 150 150 -C /data/images1/BURKITT/outdata/correct_trans20 -i 25 -n 2 -w 2 -N 4 

This runs the program on the translating tree data. The central
image is 20 so it uses images 19 and 21 as well. [Use the -s option
to use images farther away from the central image, for example -s 5
means use images 15, 20 and 25.] The next two arguments indicate directories
where the input image sequence is and where the output velocity files
go. -C means the correct velocity file is to be specified and
error analysis is to be performed. All options starting with -'s are,
of course, optional and must occur after the fixed arguments. 
-i specifies the maximum number of iterations to be performed for step2
of Singh's algorithm (the default is 10).
-n specifies the window size for the computation of SSD values, the
default is 2.
-w specifies the window size used in step 2, default is 1 (and it can 
only be 1 or 2). 
-N specifies the maximum displacement, the default and maximum is 4. 
If you want to measure faster motions don't use this program as it
doesn't use a Laplacian pyramid. We were only interested in differentiable 
motions which tend to small...)

This program is verbose so directing the program's output to another
file is a good idea. As with our other programs, the program generate 
the file names for the output velocity data. These names will be printed
and are constructed using the values of n, w and N as well as the sequence
name.

There are lots of other options. For example:

singh newbinarytreet. 20 /data/images1/BURKITT/testdata /data/images2/SINGH -C /data/images1/BURKITT/outdata/correct_trans20 -i 25 -n 2 -w 2 -N 4 -P1 -P2 -PR1
-PR2 -T1 0.0 10.0 20 -T2 0.0 1.0 20 

-P1 and -P2 specify that neither step 1 or step 2 should be performed,
instead read the old velocity and covariance matrix files to set
things up. This is good if you just want to do error analysis.
-T1 and -T2 indicate that thresholding is to be performed after
steps 1 and 2 respectively. Thresholding is done on the smallest
eigenvalues of the covariance matrices. So -T1 0.0 10.0 20
means use 20 thresholds evenly spaced from 0.0 to 10.0 in 0.5
increments. Similarly for -T2.
-PR1 and -PR2 mean all the velocity fields generated by -T1 or -T2
are printed. Yup, this takes a lot of space but lets you see visually
the effects of thresholding.

Other options:
-PRI - print the flow field after each iteration of step 2 (lots
of disk space required). 
-PRL - print out the three Laplacian images used
-NL - Don't use Laplacian images (but the original ones unchanged).
-SUB - a useful feature. Its lets you perform steps 1 and 2 of Singh's
algorithm on a subset of the image. -SUB 100 100 25 25 would
perform Singh's velocity calculation on a subimage sequence
with upper left corner 100 100 and size 25 by 25. Note that results
for step 1 will be the same as if the whole image had been used
but this is not the case for step 2 (because of the global effects
of the smoothing). This option is fragile as it hasn't been tested
extensively. 
Of course the -B option exists to let you use raw binary data.

